{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_learning_whitepapaer_16.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOhj78f0qi1suOeBRBhV73S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khalidpark/whitepaper-DeepLearning/blob/main/deep_learning_whitepapaer_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXn15KKCffXx"
      },
      "source": [
        "Attention을 구현한 코드를 실행해보도록 하겠습니다.\n",
        "\n",
        "- **모듈 임포트 / 텍스트 전처리**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-gJBkcrfcM7"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67Sm3kyRfuyu",
        "outputId": "dfc22360-4e20-44e1-c3a9-d0405afda072"
      },
      "source": [
        "# Download the file\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roj-oDN9fz3D"
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "                 if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ljYaCtQf4VT",
        "outputId": "bc0a509e-32c6-4de3-eb4f-ca8143862123"
      },
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra76W5Hkf7QP"
      },
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  word_pairs = [[preprocess_sentence(w) for w in line.split('\\t')]\n",
        "                for line in lines[:num_examples]]\n",
        "\n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZLq0gWxf9_R",
        "outputId": "3cf4dcaa-1095-4fa5-cbfc-7b7d083c974d"
      },
      "source": [
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwo7oj6WgAY5"
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqPktihKgCqs"
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xJxnsOviQ7Y"
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJzfJMD2iRm7",
        "outputId": "7d0657cf-bc7b-41e2-de01-c727c1ecb464"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24000 24000 6000 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNcJ5CiHgo7M"
      },
      "source": [
        "- **설정하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gyhFLuRg0VP"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ngvIQ5xg2WP",
        "outputId": "391d2838-a484-4c47-e206-84937663e471"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 16]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoFkIUrQhEjZ"
      },
      "source": [
        "- **인코더 구현**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrVGkNVYhDkG"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0p3wzwMhNbb",
        "outputId": "234a2fe1-4818-4920-b7e7-2ccf3d60c96a"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print('Encoder output shape: (batch size, sequence length, units)', sample_output.shape)\n",
        "print('Encoder Hidden state shape: (batch size, units)', sample_hidden.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoB8eAG_hPls"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yej3jZPdhSCL",
        "outputId": "092f4540-6448-40e5-9b46-1987af3af50b"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units)\", attention_result.shape)\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1)\", attention_weights.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gui7f8kVhYhC"
      },
      "source": [
        "- **디코더 구현**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V_tdtO2hT1b"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Lkg44lphcGZ",
        "outputId": "ad8a0c61-234e-4f9d-8d9c-070c36474665"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print('Decoder output shape: (batch_size, vocab size)', sample_decoder_output.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGEjBTgDheMw"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
        "                                                            reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUhuss6ChgiY"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MRQ6Ulhh0VW",
        "outputId": "11af68c3-abe3-4b1e-80eb-c06104de595e"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "      \n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.4683\n",
            "Epoch 1 Batch 100 Loss 2.1938\n",
            "Epoch 1 Batch 200 Loss 1.9613\n",
            "Epoch 1 Batch 300 Loss 1.7417\n",
            "Epoch 1 Loss 2.0422\n",
            "Time taken for 1 epoch 46.22278356552124 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.5168\n",
            "Epoch 2 Batch 100 Loss 1.5228\n",
            "Epoch 2 Batch 200 Loss 1.4626\n",
            "Epoch 2 Batch 300 Loss 1.2586\n",
            "Epoch 2 Loss 1.3963\n",
            "Time taken for 1 epoch 30.171414613723755 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.0841\n",
            "Epoch 3 Batch 100 Loss 1.0435\n",
            "Epoch 3 Batch 200 Loss 1.0328\n",
            "Epoch 3 Batch 300 Loss 0.9237\n",
            "Epoch 3 Loss 0.9970\n",
            "Time taken for 1 epoch 29.69036841392517 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.7266\n",
            "Epoch 4 Batch 100 Loss 0.7611\n",
            "Epoch 4 Batch 200 Loss 0.7630\n",
            "Epoch 4 Batch 300 Loss 0.6965\n",
            "Epoch 4 Loss 0.6864\n",
            "Time taken for 1 epoch 29.884901523590088 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.5178\n",
            "Epoch 5 Batch 100 Loss 0.4143\n",
            "Epoch 5 Batch 200 Loss 0.4975\n",
            "Epoch 5 Batch 300 Loss 0.4387\n",
            "Epoch 5 Loss 0.4699\n",
            "Time taken for 1 epoch 29.732314109802246 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7aJioMoiYx1"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L9MXJY9iZhv"
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLJ37OOOib_L"
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "93IpAAFMi9Yb",
        "outputId": "60903f9d-ec38-451d-82ef-1f7127ebafee"
      },
      "source": [
        "translate(u'hace mucho frio aqui.')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translation: it s very cold here . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "_uQW40H-jAYu",
        "outputId": "3a1a1730-8d51-4473-a1af-39e393466346"
      },
      "source": [
        "translate(u'esta es mi vida.')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> esta es mi vida . <end>\n",
            "Predicted translation: this is my life . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y9W20irk9mO"
      },
      "source": [
        "-----------------------------\n",
        "------------------------"
      ]
    }
  ]
}